### **Google Cloud Storage (`google-cloud-storage`) Guide**

The `google-cloud-storage` Python library is used to interact with  **Google Cloud Storage (GCS)** , enabling file uploads, downloads, and management of cloud storage buckets.

---

## **1Ô∏è‚É£ Install `google-cloud-storage`**

```bash
pip install google-cloud-storage
```

‚úÖ  **Dependencies** : Requires  **Python 3.7+** .

---

## **2Ô∏è‚É£ Set Up Authentication**

You need a  **Google Cloud Service Account Key** .

1. Go to [Google Cloud Console](https://console.cloud.google.com/).
2. Navigate to  **IAM & Admin ‚Üí Service Accounts** .
3. Create a service account and download the  **JSON key file** .

Then, set the environment variable:

```bash
export GOOGLE_APPLICATION_CREDENTIALS="path/to/service-account.json"
```

‚úÖ **Use Case:** Required for authenticated access to GCS.

---

## **3Ô∏è‚É£ Upload a File to GCS**

```python
from google.cloud import storage

def upload_to_gcs(bucket_name, source_file, destination_blob):
    client = storage.Client()
    bucket = client.bucket(bucket_name)
    blob = bucket.blob(destination_blob)

    blob.upload_from_filename(source_file)
    print(f"File {source_file} uploaded to {destination_blob}.")

upload_to_gcs("your-bucket-name", "local_file.txt", "uploaded_file.txt")
```

‚úÖ **Use Case:** Uploads a file to a  **GCS bucket** .

---

## **4Ô∏è‚É£ Download a File from GCS**

```python
def download_from_gcs(bucket_name, blob_name, destination_file):
    client = storage.Client()
    bucket = client.bucket(bucket_name)
    blob = bucket.blob(blob_name)

    blob.download_to_filename(destination_file)
    print(f"File {blob_name} downloaded to {destination_file}.")

download_from_gcs("your-bucket-name", "uploaded_file.txt", "downloaded.txt")
```

‚úÖ **Use Case:** Downloads a file from  **GCS to local storage** .

---

## **5Ô∏è‚É£ List Files in a Bucket**

```python
def list_files(bucket_name):
    client = storage.Client()
    bucket = client.bucket(bucket_name)

    blobs = bucket.list_blobs()
    for blob in blobs:
        print(blob.name)

list_files("your-bucket-name")
```

‚úÖ **Use Case:** Lists all files in a  **GCS bucket** .

---

## **6Ô∏è‚É£ Delete a File from GCS**

```python
def delete_from_gcs(bucket_name, blob_name):
    client = storage.Client()
    bucket = client.bucket(bucket_name)
    blob = bucket.blob(blob_name)

    blob.delete()
    print(f"Deleted {blob_name} from {bucket_name}.")

delete_from_gcs("your-bucket-name", "uploaded_file.txt")
```

‚úÖ **Use Case:** Deletes a file from  **GCS** .

---

## **7Ô∏è‚É£ Generate a Signed URL (Temporary Access)**

```python
from datetime import timedelta

def generate_signed_url(bucket_name, blob_name, expiration_minutes=60):
    client = storage.Client()
    bucket = client.bucket(bucket_name)
    blob = bucket.blob(blob_name)

    url = blob.generate_signed_url(expiration=timedelta(minutes=expiration_minutes))
    print(f"Signed URL: {url}")

generate_signed_url("your-bucket-name", "uploaded_file.txt", 60)
```

‚úÖ **Use Case:** Grants **temporary access** to a file.

---

## **8Ô∏è‚É£ Interview Questions on `google-cloud-storage`**

### **1Ô∏è‚É£ Basic Questions**

‚úî What is  **Google Cloud Storage (GCS)** ?

‚úî How do you authenticate to GCS in Python?

‚úî How do you upload/download a file using `google-cloud-storage`?

### **2Ô∏è‚É£ Advanced Questions**

‚úî What is a  **signed URL** , and how do you use it?

‚úî How can you improve performance when working with **large files** in GCS?

‚úî What is the difference between  **Coldline, Nearline, and Standard storage classes** ?

‚úî How do you **stream data to/from GCS** without saving it locally?

---

## **üöÄ Next Steps**

Would you like an **end-to-end GCS integration** with FastAPI or Flask? üéØ
